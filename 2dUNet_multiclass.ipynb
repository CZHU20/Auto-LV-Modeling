{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2dUNet_multiclass.ipynb","version":"0.3.2","provenance":[{"file_id":"1SOkz5E4ES9ai8nWABtrWr4T4Lb-64k88","timestamp":1552428453032}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"qnq4k2sUVqc6","colab_type":"code","outputId":"1e983f67-d131-425d-b032-c5514c365a1e","executionInfo":{"status":"ok","timestamp":1553707758386,"user_tz":420,"elapsed":1711,"user":{"displayName":"Fanwei Kong","photoUrl":"","userId":"05426665111850906095"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"id":"20JY_57XMQSk","colab_type":"code","colab":{}},"cell_type":"code","source":["import os\n","import glob\n","import functools\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","mpl.rcParams['axes.grid'] = False\n","mpl.rcParams['figure.figsize'] = (12,12)\n","\n","from sklearn.model_selection import train_test_split\n","import matplotlib.image as mpimg\n","import pandas as pd\n","from PIL import Image"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pC8JhVirNPhT","colab_type":"code","colab":{}},"cell_type":"code","source":["import tensorflow as tf\n","import tensorflow.contrib as tfcontrib\n","from tensorflow.python.keras import layers\n","from tensorflow.python.keras import losses\n","from tensorflow.python.keras import models\n","from tensorflow.python.keras import backend as K  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"CsVyNiENNZNw","colab_type":"code","outputId":"ef603cae-57f5-40b1-ae5b-4c6e556e07cf","executionInfo":{"status":"ok","timestamp":1553707772541,"user_tz":420,"elapsed":12623,"user":{"displayName":"Fanwei Kong","photoUrl":"","userId":"05426665111850906095"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["!pip install SimpleITK"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: SimpleITK in /usr/local/lib/python3.6/dist-packages (1.2.0)\n"],"name":"stdout"}]},{"metadata":{"id":"98J6wTxKNmei","colab_type":"code","colab":{}},"cell_type":"code","source":["import h5py\n","import SimpleITK as sitk"],"execution_count":0,"outputs":[]},{"metadata":{"id":"sQ9I8UvsOrTy","colab_type":"text"},"cell_type":"markdown","source":["Find training data filenames and label filenames "]},{"metadata":{"id":"TpPHHbP3OqVX","colab_type":"code","colab":{}},"cell_type":"code","source":["def getTrainNLabelNames(data_folder, m, ext='*.nii.gz'):\n","  x_train_filenames = []\n","  y_train_filenames = []\n","  for subject_dir in sorted(glob.glob(os.path.join(data_folder,m+'_train',ext))):\n","      x_train_filenames.append(os.path.realpath(subject_dir))\n","  for subject_dir in sorted(glob.glob(os.path.join(data_folder ,m+'_train_masks',ext))):\n","      y_train_filenames.append(os.path.realpath(subject_dir))\n","  return x_train_filenames, y_train_filenames\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mPxXL1b_P3zh","colab_type":"text"},"cell_type":"markdown","source":["Convert 3D data to 2D data"]},{"metadata":{"id":"vGQd1B8jzd10","colab_type":"code","colab":{}},"cell_type":"code","source":["def swapLabels(labels):\n","    labels[labels==421]=420\n","    unique_label = np.unique(labels)\n","\n","    new_label = range(len(unique_label))\n","    for i in range(len(unique_label)):\n","        label = unique_label[i]\n","        print(label)\n","        newl = new_label[i]\n","        print(newl)\n","        labels[labels==label] = newl\n","       \n","    print(unique_label)\n","\n","    return labels"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4V2ZfGqIGToy","colab_type":"code","colab":{}},"cell_type":"code","source":["def RescaleIntensity(slice_im,m):\n","  #slice_im: numpy array\n","  #m: modality, ct or mr\n","  if m ==\"ct\":\n","    slice_im[slice_im>750] = 750\n","    slice_im[slice_im<-750] = -750\n","    slice_im = slice_im/750\n","  elif m==\"mr\":\n","#     top_10 = np.percentile(slice_im,90)\n","#     above = slice_im[slice_im>top_10]\n","#     med = np.median(above)\n","#     slice_im = slice_im/med\n","#     slice_im[slice_im>1.] = 1.\n","#     slice_im = slice_im*2.-1.\n","    slice_im[slice_im>1500] = 1500\n","    slice_im = (slice_im-750)/750\n","  return slice_im\n","    "],"execution_count":0,"outputs":[]},{"metadata":{"id":"0zqLRPRl0oes","colab_type":"code","colab":{}},"cell_type":"code","source":["def np_to_tfrecords(X, Y, file_path_prefix, verbose=True):\n","    def _bytes_feature(value):\n","      \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n","      return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n","\n","    def _float_feature(value):\n","      \"\"\"Returns a float_list from a float / double.\"\"\"\n","      return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n","\n","    def _int64_feature(value):\n","      \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n","      return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n","            \n","    if Y is not None:\n","        assert X.shape == Y.shape\n","    \n","    # Generate tfrecord writer\n","    result_tf_file = file_path_prefix + '.tfrecords'\n","    writer = tf.python_io.TFRecordWriter(result_tf_file)\n","    if verbose:\n","        print(\"Serializing example into {}\".format(result_tf_file))\n","        \n","    # iterate over each sample,\n","    # and serialize it as ProtoBuf.\n","    \n","    d_feature = {}\n","    d_feature['X'] = _float_feature(X.flatten())\n","    if Y is not None:\n","        d_feature['Y'] = _int64_feature(Y.flatten())\n","    d_feature['shape0'] = _int64_feature([X.shape[0]])\n","    d_feature['shape1'] = _int64_feature([X.shape[1]])\n","            \n","    features = tf.train.Features(feature=d_feature)\n","    example = tf.train.Example(features=features)\n","    serialized = example.SerializeToString()\n","    writer.write(serialized)\n","    \n","    if verbose:\n","        print(\"Writing {} done!\".format(result_tf_file))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oW8mu-jbPMUX","colab_type":"code","colab":{}},"cell_type":"code","source":["def data_preprocess(modality,data_folder,view, data_folder_out):\n","  train_img_path = []\n","  train_mask_path = []\n","  train_weights = []\n","  for m in modality:\n","    imgVol_fn, mask_fn = getTrainNLabelNames(data_folder, m)\n","    print(\"number of training data %d\" % len(imgVol_fn))\n","    assert len(imgVol_fn) == len(mask_fn)\n","\n","    for i in range(0,len(imgVol_fn)):\n","      img_path = imgVol_fn[i]\n","      mask_path = mask_fn[i]\n","      imgVol = sitk.GetArrayFromImage(sitk.ReadImage(img_path))  # numpy array\n","      imgVol = RescaleIntensity(imgVol, m)\n","      #imgVol = HistogramEqualization(imgVol)\n","      maskVol = sitk.GetArrayFromImage(sitk.ReadImage(mask_path))  # numpy array\n","      maskVol = swapLabels(maskVol)\n","      if m ==\"mr\":\n","        imgVol = np.moveaxis(imgVol,0,-1)\n","        maskVol = np.moveaxis(maskVol,0,-1)\n","      print(\"number of image slices in this view %d\" % imgVol.shape[view])\n","      for sid in range(imgVol.shape[view]):\n","        out_im_path = os.path.join(data_folder_out, m+'_train', m+'_train'+str(i)+'_'+str(sid))\n","        out_msk_path = os.path.join(data_folder_out, m+'_train_masks',  m+'_train_mask'+str(i)+'_'+str(sid))\n","        slice_im = np.moveaxis(imgVol,view,0)[sid,:,:]\n","        slice_msk = np.moveaxis(maskVol,view,0)[sid,:,:]\n","        #slice_im = HistogramEqualization(slice_im)\n","        #sitk.WriteImage(sitk.Cast(sitk.RescaleIntensity(sitk.GetImageFromArray(slice_im.astype(np.uint16))), sitk.sitkUInt8),out_im_path+'.png')\n","        #sitk.WriteImage(sitk.Cast(sitk.RescaleIntensity(sitk.GetImageFromArray((slice_msk).astype(np.uint16))), sitk.sitkUInt8), out_msk_path+'.png')\n","        #np.save(out_im_path+'.npy',RescaleIntensity(slice_im,m))\n","        #np.save(out_msk_path+'.npy',slice_msk)\n","        np_to_tfrecords(slice_im.astype(np.float32),slice_msk.astype(np.int64), out_im_path, verbose=True)\n","        train_img_path.append(out_im_path)\n","        train_mask_path.append(out_msk_path)\n","    #train_weights+=list(np.ones(num).astype(int))\n","  return train_img_path, train_mask_path"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WxJQGJzuJnnE","colab_type":"code","colab":{}},"cell_type":"code","source":["np.random.seed(10)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-Ks9JvlV1EI3","colab_type":"code","colab":{}},"cell_type":"code","source":["def sample(iterable, n):\n","    \"\"\"\n","    Returns @param n random items from @param iterable.\n","    \"\"\"\n","    if n == 0:\n","      return []\n","    reservoir = []\n","    factor = int(np.ceil(float(n)/float(len(iterable))))\n","    for i in range(0,factor-1):\n","      iterable+=iterable\n","    for t, item in enumerate(iterable):\n","        if t < n:\n","            reservoir.append(item)\n","        else:\n","            m = np.random.randint(0,t)\n","            if m < n:\n","                reservoir[m] = item\n","    return reservoir"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kFKwMXSFix2h","colab_type":"code","outputId":"7c768c57-c5d0-4346-d2ba-d2163a91aa93","executionInfo":{"status":"ok","timestamp":1553707808237,"user_tz":420,"elapsed":36065,"user":{"displayName":"Fanwei Kong","photoUrl":"","userId":"05426665111850906095"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"cell_type":"code","source":["modality = [\"ct\", \"mr\"]\n","data_folder = '/content/gdrive/My Drive/ImageData/MMWHS'\n","view = 1\n","data_folder_out = '/content/gdrive/My Drive/ImageData/MMWHS/2d_multiclass-coronal'\n","print(\"Making dir...\")\n","try:\n","  os.mkdir(data_folder_out)\n","except Exception as e: print(e)\n","for m in modality:\n","  try:\n","    os.mkdir(os.path.join(data_folder_out, m+'_train'))\n","    os.mkdir(os.path.join(data_folder_out, m+'_train_masks'))\n","  except Exception as e: print(e)\n","\n","overwrite = False\n","if overwrite:\n","  _, _  = data_preprocess(modality,data_folder,view, data_folder_out)\n","\n","x_train_filenames = []\n","x_weights = []\n","filenames = [None]*len(modality)\n","nums = np.zeros(len(modality))\n","for i, m in enumerate(modality):\n","  filenames[i], _ = getTrainNLabelNames(data_folder_out, m, ext='*.tfrecords')\n","  nums[i] = len(filenames[i])\n","  x_train_filenames+=filenames[i]\n","  print(nums)\n","\n","#nums = np.max(nums) - nums\n","#for i , _ in enumerate(modality):\n","#  index = sample(range(len(filenames[i])), nums[i])\n","#  x_train_filenames+=[filenames[i][j] for j in index]\n","    \n","print(len(x_train_filenames))\n"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Making dir...\n","[Errno 17] File exists: '/content/gdrive/My Drive/ImageData/MMWHS/2d_multiclass-coronal'\n","[Errno 17] File exists: '/content/gdrive/My Drive/ImageData/MMWHS/2d_multiclass-coronal/ct_train'\n","[Errno 17] File exists: '/content/gdrive/My Drive/ImageData/MMWHS/2d_multiclass-coronal/mr_train'\n","[10240.     0.]\n","[10240.  7124.]\n","17364\n"],"name":"stdout"}]},{"metadata":{"id":"EyYLCJ8CjEjB","colab_type":"code","outputId":"452a7025-03f1-4375-fc6b-a0e8878f7a18","executionInfo":{"status":"ok","timestamp":1553707808239,"user_tz":420,"elapsed":32498,"user":{"displayName":"Fanwei Kong","photoUrl":"","userId":"05426665111850906095"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"cell_type":"code","source":["\n","#x_train_filenames = [i+'.tfrecords' for i in x_train_filenames]\n","#y_train_filenames = [i+'.tfrecords' for i in y_train_filenames]\n","#x_train_filenames, x_val_filenames, y_train_filenames, y_val_filenames = \\\n","#                    train_test_split(x_train_filenames, y_train_filenames, test_size=0.2, random_state=42)\n","#x_train_filenames, x_val_filenames, x_train_weights,_ = train_test_split(x_train_filenames, x_weights, test_size=0.2, random_state=42)\n","x_train_filenames, x_val_filenames = train_test_split(x_train_filenames, test_size=0.2, random_state=42)\n","num_train_examples = len(x_train_filenames)\n","num_val_examples = len(x_val_filenames)\n","\n","print(\"Number of training examples: {}\".format(num_train_examples))\n","print(\"Number of validation examples: {}\".format(num_val_examples))\n","\n","x_train_filenames[:10]\n","#y_train_filenames[:10]\n"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Number of training examples: 13891\n","Number of validation examples: 3473\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["['/content/gdrive/My Drive/ImageData/MMWHS/2d_multiclass-coronal/ct_train/ct_train10_311.tfrecords',\n"," '/content/gdrive/My Drive/ImageData/MMWHS/2d_multiclass-coronal/ct_train/ct_train10_188.tfrecords',\n"," '/content/gdrive/My Drive/ImageData/MMWHS/2d_multiclass-coronal/mr_train/mr_train0_115.tfrecords',\n"," '/content/gdrive/My Drive/ImageData/MMWHS/2d_multiclass-coronal/ct_train/ct_train18_315.tfrecords',\n"," '/content/gdrive/My Drive/ImageData/MMWHS/2d_multiclass-coronal/mr_train/mr_train5_112.tfrecords',\n"," '/content/gdrive/My Drive/ImageData/MMWHS/2d_multiclass-coronal/ct_train/ct_train9_483.tfrecords',\n"," '/content/gdrive/My Drive/ImageData/MMWHS/2d_multiclass-coronal/mr_train/mr_train1_61.tfrecords',\n"," '/content/gdrive/My Drive/ImageData/MMWHS/2d_multiclass-coronal/mr_train/mr_train6_86.tfrecords',\n"," '/content/gdrive/My Drive/ImageData/MMWHS/2d_multiclass-coronal/mr_train/mr_train13_217.tfrecords',\n"," '/content/gdrive/My Drive/ImageData/MMWHS/2d_multiclass-coronal/mr_train/mr_train3_121.tfrecords']"]},"metadata":{"tags":[]},"execution_count":14}]},{"metadata":{"id":"3pHi85vMjxyI","colab_type":"text"},"cell_type":"markdown","source":["# Visualize\n","Let's take a look at some of the examples of different images in our dataset. "]},{"metadata":{"id":"6RifTQgZgQx3","colab_type":"code","colab":{}},"cell_type":"code","source":["# display_num = 5\n","\n","# r_choices = np.random.choice(num_train_examples, display_num)\n","\n","# plt.figure(figsize=(10, 15))\n","# for i in range(0, display_num * 2, 2):\n","#   img_num = r_choices[i // 2]\n","#   x_pathname = x_train_filenames[img_num]\n","#   y_pathname = y_train_filenames[img_num]\n","  \n","#   plt.subplot(display_num, 2, i + 1)\n","#   plt.imshow(mpimg.imread(x_pathname))\n","  \n","#   plt.title(\"Original Image\")\n","  \n","#   example_labels = mpimg.imread(y_pathname)\n","#   label_vals = np.unique(example_labels)\n","#   print(label_vals)\n","  \n","#   plt.subplot(display_num, 2, i + 2)\n","#   plt.imshow(example_labels)\n","#   plt.title(\"Masked Image\")  \n","  \n","# plt.suptitle(\"Examples of Images and their Masks\")\n","# plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5KZuVDy3k5GN","colab_type":"text"},"cell_type":"markdown","source":["# Set up "]},{"metadata":{"id":"ENd2PrBYkmvn","colab_type":"code","colab":{}},"cell_type":"code","source":["img_shape = (256, 256, 1)\n","num_class = 8\n","batch_size = 8\n","epochs = 300"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hPt06XrelKuz","colab_type":"text"},"cell_type":"markdown","source":["# Build our input pipeline with `tf.data`\n","\n"]},{"metadata":{"id":"OZVKgX07nujo","colab_type":"text"},"cell_type":"markdown","source":["## Shifting the image"]},{"metadata":{"id":"AfBVk4MBny0o","colab_type":"code","colab":{}},"cell_type":"code","source":["def shift_img(output_img, label_img, width_shift_range, height_shift_range):\n","  \"\"\"This fn will perform the horizontal or vertical shift\"\"\"\n","  if width_shift_range or height_shift_range:\n","      if width_shift_range:\n","        width_shift_range = tf.random_uniform([], \n","                                              -width_shift_range * img_shape[1],\n","                                              width_shift_range * img_shape[1])\n","      if height_shift_range:\n","        height_shift_range = tf.random_uniform([],\n","                                               -height_shift_range * img_shape[0],\n","                                               height_shift_range * img_shape[0])\n","      # Translate both \n","      output_img = tfcontrib.image.translate(output_img,\n","                                             [width_shift_range, height_shift_range])\n","      label_img = tfcontrib.image.translate(label_img,\n","                                             [width_shift_range, height_shift_range])\n","  return output_img, label_img"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ucasp9Ihn_ue","colab_type":"text"},"cell_type":"markdown","source":["## Flipping the image randomly "]},{"metadata":{"id":"80Q_Lshfn-7G","colab_type":"code","colab":{}},"cell_type":"code","source":["def flip_img(horizontal_flip, tr_img, label_img):\n","  if horizontal_flip:\n","    flip_prob = tf.random_uniform([], 0.0, 1.0)\n","    tr_img, label_img = tf.cond(tf.less(flip_prob, 0.5),\n","                                lambda: (tf.image.flip_left_right(tr_img), tf.image.flip_left_right(label_img)),\n","                                lambda: (tr_img, label_img))\n","  return tr_img, label_img"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CsSlAsxXX_Pf","colab_type":"text"},"cell_type":"markdown","source":["##Scale/shift the image intensity randomly"]},{"metadata":{"id":"hVlkxm0lX-Xb","colab_type":"code","colab":{}},"cell_type":"code","source":["def changeIntensity_img(tr_img, label_img, changeIntensity=False):\n","  if changeIntensity:\n","    scale = tf.random_uniform([], 0.9, 1.1)\n","    shift = tf.random_uniform([], -0.1, 0.1)\n","    tr_img = tr_img*scale+shift\n","    \n","  return tr_img, label_img\n","  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"Z9sSeukQoGLd","colab_type":"text"},"cell_type":"markdown","source":["## Assembling our transformations into our augment function\n"]},{"metadata":{"id":"JFBhbfBCoFud","colab_type":"code","colab":{}},"cell_type":"code","source":["def _augment(img,\n","             label_img,\n","             resize=None,  # Resize the image to some size e.g. [256, 256]\n","             horizontal_flip=False,  # Random left right flip,\n","             changeIntensity=False,\n","             width_shift_range=0,  # Randomly translate the image horizontally\n","             height_shift_range=0):  # Randomly translate the image vertically \n","  if resize is not None:\n","    # Resize both images\n","    label_img = tf.image.resize_images(label_img, resize, method=tf.image.ResizeMethod.NEAREST_NEIGHBOR, align_corners=True)\n","    img = tf.image.resize_images(img, resize, method=tf.image.ResizeMethod.NEAREST_NEIGHBOR, align_corners=True)\n","  \n","  \n","  img, label_img = flip_img(horizontal_flip, img, label_img)\n","  img, label_img = shift_img(img, label_img, width_shift_range, height_shift_range)\n","  img, label_img = changeIntensity_img(img, label_img,changeIntensity )\n","  return img, label_img"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Xq5qr8GBnt5o","colab_type":"text"},"cell_type":"markdown","source":["## Processing each pathname"]},{"metadata":{"id":"eH1eHcfm2OyL","colab_type":"code","colab":{}},"cell_type":"code","source":["def _parse_function(example_proto):\n","  features = {\"X\": tf.VarLenFeature(tf.float32),\n","              \"Y\": tf.VarLenFeature(tf.int64),\n","              \"shape0\": tf.FixedLenFeature((), tf.int64),\n","              \"shape1\": tf.FixedLenFeature((), tf.int64)}\n","  parsed_features = tf.parse_single_example(example_proto, features)\n","  img = tf.sparse_tensor_to_dense(parsed_features[\"X\"])\n","  height = tf.cast(parsed_features[\"shape0\"], tf.int32)\n","  width = tf.cast(parsed_features[\"shape1\"], tf.int32)\n","  print(img,parsed_features)\n","  label = tf.sparse_tensor_to_dense(parsed_features[\"Y\"])\n","  img = tf.reshape(img, tf.stack([height, width,1]))\n","  label = tf.reshape(label, tf.stack([height, width,1]) )\n","  label = tf.cast(label, tf.int32)\n","  return img, label"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bH0myn2ElEcj","colab_type":"code","colab":{}},"cell_type":"code","source":["def _process_pathnames(fname):\n","  # We map this function onto each pathname pair  \n","  dataset_str = tf.read_file(fname)\n","  dataset = tf.data.TFRecordDataset(dataset_str)\n","  parsed_features = dataset.map(_parse_function)\n","  \n","  iterator = dataset.make_one_shot_iterator()\n","  #data = iterator.get_next()\n","  \n","  img = tf.sparse_tensor_to_dense(parsed_features[\"X\"])\n","  height = tf.cast(parsed_features[\"shape0\"], tf.int32)\n","  width = tf.cast(parsed_features[\"shape1\"], tf.int32)\n","  label = tf.sparse_tensor_to_dense(parsed_features[\"Y\"])\n","  img = tf.reshape(img, tf.stack([height, width]))\n","  label = tf.reshape(label, tf.stack([height, width]) )\n","\n","  print(img, label)\n","  return img, label"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lXJzRI1fVVn-","colab_type":"text"},"cell_type":"markdown","source":["##Assemble Dataset"]},{"metadata":{"id":"kAmcMwVAoVDr","colab_type":"code","colab":{}},"cell_type":"code","source":["def get_baseline_dataset(filenames, preproc_fn=functools.partial(_augment),\n","                         threads=5, \n","                         batch_size=batch_size,\n","                         shuffle=True):           \n","  num_x = len(filenames)\n","  # Create a dataset from the filenames and labels\n","  files = tf.data.Dataset.from_tensor_slices(filenames)\n","  print(files)\n","  \n","  dataset = files.apply(tf.contrib.data.parallel_interleave(\n","    tf.data.TFRecordDataset, cycle_length=threads))\n","  # Map our preprocessing function to every element in our dataset, taking\n","  # advantage of multithreading\n","  dataset = dataset.map(_parse_function, num_parallel_calls=threads)\n","  # dataset = dataset.map(_process_pathnames, num_parallel_calls=threads)\n","  if preproc_fn.keywords is not None and 'resize' not in preproc_fn.keywords:\n","    assert batch_size == 1, \"Batching images must be of the same size\"\n","\n","  dataset = dataset.map(preproc_fn, num_parallel_calls=threads)\n","  print(num_x)\n","  if shuffle:\n","    dataset = dataset.shuffle(int(num_x/2))\n","  \n","  \n","  # It's necessary to repeat our data for all epochs \n","  dataset = dataset.repeat().batch(batch_size)\n","  dataset = dataset.prefetch(buffer_size=batch_size)\n","\n","  return dataset"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hNR6OKvPoevB","colab_type":"text"},"cell_type":"markdown","source":["## Set up train and validation datasets\n","Note that we apply image augmentation to our training dataset but not our validation dataset. "]},{"metadata":{"id":"C_P8CgKWodni","colab_type":"code","colab":{}},"cell_type":"code","source":["tr_cfg = {\n","    'resize': [img_shape[0], img_shape[1]],\n","    'horizontal_flip': True,\n","    'changeIntensity': True,\n","    'width_shift_range': 0.1,\n","    'height_shift_range': 0.1\n","}\n","tr_preprocessing_fn = functools.partial(_augment, **tr_cfg)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"G1gXQVCopCTe","colab_type":"code","colab":{}},"cell_type":"code","source":["val_cfg = {\n","    'resize': [img_shape[0], img_shape[1]],\n","}\n","val_preprocessing_fn = functools.partial(_augment, **val_cfg)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8EbytoE_pGHD","colab_type":"code","outputId":"3e2a1581-2027-4791-a948-e60cc4f46867","executionInfo":{"status":"ok","timestamp":1553707820410,"user_tz":420,"elapsed":1348,"user":{"displayName":"Fanwei Kong","photoUrl":"","userId":"05426665111850906095"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"cell_type":"code","source":["train_ds = get_baseline_dataset(x_train_filenames, preproc_fn=tr_preprocessing_fn,\n","                                batch_size=batch_size)\n","val_ds = get_baseline_dataset(x_train_filenames, preproc_fn=val_preprocessing_fn,\n","                              batch_size=batch_size)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["<DatasetV1Adapter shapes: (), types: tf.string>\n","Tensor(\"SparseToDense:0\", shape=(?,), dtype=float32) {'X': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f98f73c3fd0>, 'Y': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f98f73c3da0>, 'shape0': <tf.Tensor 'ParseSingleExample/ParseSingleExample:6' shape=() dtype=int64>, 'shape1': <tf.Tensor 'ParseSingleExample/ParseSingleExample:7' shape=() dtype=int64>}\n","13891\n","<DatasetV1Adapter shapes: (), types: tf.string>\n","Tensor(\"SparseToDense:0\", shape=(?,), dtype=float32) {'X': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f98f94c9828>, 'Y': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f98f94c9c88>, 'shape0': <tf.Tensor 'ParseSingleExample/ParseSingleExample:6' shape=() dtype=int64>, 'shape1': <tf.Tensor 'ParseSingleExample/ParseSingleExample:7' shape=() dtype=int64>}\n","13891\n"],"name":"stdout"}]},{"metadata":{"id":"V3OiTBDXwTmk","colab_type":"text"},"cell_type":"markdown","source":["## Let's see if our image augmentor data pipeline is producing expected results"]},{"metadata":{"id":"I-vS3UGrwUQL","colab_type":"code","colab":{}},"cell_type":"code","source":["# temp_ds = get_baseline_dataset(x_train_filenames, \n","#                                preproc_fn=tr_preprocessing_fn,\n","#                                batch_size=5,\n","#                                shuffle=True)\n","# # Let's examine some of these augmented images\n","# data_aug_iter = temp_ds.make_one_shot_iterator()\n","# next_element = data_aug_iter.get_next()\n","# with tf.Session() as sess: \n","#   batch_of_imgs, label = sess.run(next_element)\n","\n","#   # Running next element in our graph will produce a batch of images\n","#   plt.figure(figsize=(20, 20))\n","\n","#   plt.subplot(2, 5, 1)\n","#   plt.imshow(batch_of_imgs[0,:,:,0])\n","#   plt.subplot(2, 5, 6)\n","#   plt.imshow(label[0, :, :,0])\n","  \n","#   plt.subplot(2, 5, 2)\n","#   plt.imshow(batch_of_imgs[1, :, :,0])\n","#   plt.subplot(2, 5, 7)\n","#   plt.imshow(label[1, :, :,0])\n","  \n","#   plt.subplot(2, 5, 3)\n","#   plt.imshow(batch_of_imgs[2, :, :,0])\n","#   plt.subplot(2, 5, 8)\n","#   plt.imshow(label[2, :, :,0])\n","  \n","#   plt.subplot(2, 5, 4)\n","#   plt.imshow(batch_of_imgs[3, :, :,0])\n","#   plt.subplot(2, 5, 9)\n","#   plt.imshow(label[3, :, :,0])\n","  \n","#   plt.subplot(2, 5, 5)\n","#   plt.imshow(batch_of_imgs[4, :, :,0])\n","#   plt.subplot(2, 5, 10)\n","#   plt.imshow(label[4, :, :,0])\n","#   plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mT8zD7DTceg7","colab_type":"code","colab":{}},"cell_type":"code","source":["# #sanity checks\n","# print(np.max(batch_of_imgs), np.min(batch_of_imgs))\n","# print(batch_of_imgs.shape)\n","# print(label.shape)\n","# print(np.unique(label))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"majpTJ39Fz2l","colab_type":"text"},"cell_type":"markdown","source":["# Build the model"]},{"metadata":{"id":"8J8XtwTzF0o9","colab_type":"code","colab":{}},"cell_type":"code","source":["def conv_block(input_tensor, num_filters):\n","  encoder = layers.Conv2D(num_filters, (3, 3), padding='same')(input_tensor)\n","  encoder = layers.BatchNormalization()(encoder)\n","  encoder = layers.Activation('relu')(encoder)\n","  encoder = layers.Conv2D(num_filters, (3, 3), padding='same')(encoder)\n","  encoder = layers.BatchNormalization()(encoder)\n","  encoder = layers.Activation('relu')(encoder)\n","  return encoder\n","\n","def encoder_block(input_tensor, num_filters):\n","  encoder = conv_block(input_tensor, num_filters)\n","  encoder_pool = layers.MaxPooling2D((2, 2), strides=(2, 2))(encoder)\n","  \n","  return encoder_pool, encoder\n","\n","def decoder_block(input_tensor, concat_tensor, num_filters):\n","  decoder = layers.Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(input_tensor)\n","  decoder = layers.concatenate([concat_tensor, decoder], axis=-1)\n","  decoder = layers.BatchNormalization()(decoder)\n","  decoder = layers.Activation('relu')(decoder)\n","  decoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n","  decoder = layers.BatchNormalization()(decoder)\n","  decoder = layers.Activation('relu')(decoder)\n","  decoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n","  decoder = layers.BatchNormalization()(decoder)\n","  decoder = layers.Activation('relu')(decoder)\n","  return decoder"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oR8U_-SuF2-V","colab_type":"code","colab":{}},"cell_type":"code","source":["inputs = layers.Input(shape=img_shape)\n","# 256\n","\n","encoder0_pool, encoder0 = encoder_block(inputs, 32)\n","# 128\n","\n","encoder1_pool, encoder1 = encoder_block(encoder0_pool, 64)\n","# 64\n","\n","encoder2_pool, encoder2 = encoder_block(encoder1_pool, 128)\n","# 32\n","\n","encoder3_pool, encoder3 = encoder_block(encoder2_pool, 256)\n","# 16\n","\n","encoder4_pool, encoder4 = encoder_block(encoder3_pool, 512)\n","# 8\n","\n","center = conv_block(encoder4_pool, 1024)\n","# center\n","\n","decoder4 = decoder_block(center, encoder4, 512)\n","# 16\n","\n","decoder3 = decoder_block(decoder4, encoder3, 256)\n","# 32\n","\n","decoder2 = decoder_block(decoder3, encoder2, 128)\n","# 64\n","\n","decoder1 = decoder_block(decoder2, encoder1, 64)\n","# 128\n","\n","decoder0 = decoder_block(decoder1, encoder0, 32)\n","# 256\n","\n","outputs = layers.Conv2D(num_class, (1, 1), activation='softmax', data_format=\"channels_last\")(decoder0)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PbxK9SDfF7l0","colab_type":"code","colab":{}},"cell_type":"code","source":["model = models.Model(inputs=[inputs], outputs=[outputs])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"h5m69P9OGF-G","colab_type":"code","colab":{}},"cell_type":"code","source":["def dice_coeff(y_true, y_pred):\n","    smooth = 1.\n","    # Flatten\n","    y_true_f = tf.reshape(y_true, [-1])\n","    y_pred_f = tf.reshape(y_pred, [-1])\n","    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n","    score = (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n","    return score"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6qXmaXIVGGpa","colab_type":"code","colab":{}},"cell_type":"code","source":["from tensorflow.python.keras.utils import to_categorical\n","def dice_loss(y_true, y_pred):\n","    y_true_one_hot = tf.one_hot(tf.cast(y_true,tf.int32), num_class)\n","    loss = 0.\n","    weights = [1.,1.,1.,1.,1.,1.,1.,1.]\n","    for i in range(num_class):\n","      loss += weights[i]*(1 - dice_coeff(y_true_one_hot[:,:,:,:,i], y_pred[:,:,:,i]))\n","    return loss"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9HTK0Rw9GI-q","colab_type":"code","colab":{}},"cell_type":"code","source":["def bce_dice_loss(y_true, y_pred):\n","    loss = losses.sparse_categorical_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n","    return loss"],"execution_count":0,"outputs":[]},{"metadata":{"id":"m1t9fDJgQuSZ","colab_type":"code","colab":{}},"cell_type":"code","source":["def la_loss(y_true, y_pred):\n","    y_true_one_hot = tf.one_hot(tf.cast(y_true,tf.int32), num_class)\n","    loss = 1 - dice_coeff(y_true_one_hot[:,:,:,:,2], y_pred[:,:,:,2])\n","    return loss\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cU9G_SD7GLNr","colab_type":"code","outputId":"c1acb4b9-67aa-495f-8d75-a151782c29a7","executionInfo":{"status":"ok","timestamp":1553707835418,"user_tz":420,"elapsed":2524,"user":{"displayName":"Fanwei Kong","photoUrl":"","userId":"05426665111850906095"}},"colab":{"base_uri":"https://localhost:8080/","height":3383}},"cell_type":"code","source":["from tensorflow.python.keras.optimizers import Adam\n","adam = Adam(lr=0.02, beta_1=0.9, beta_2=0.999, epsilon=None, decay=1e-6, amsgrad=False)\n","model.compile(optimizer=adam, loss=bce_dice_loss, metrics=[dice_loss])\n","\n","model.summary()"],"execution_count":34,"outputs":[{"output_type":"stream","text":["__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 256, 256, 1)  0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 256, 256, 32) 320         input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_v1 (BatchNo (None, 256, 256, 32) 128         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 256, 256, 32) 0           batch_normalization_v1[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 256, 256, 32) 9248        activation[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_v1_1 (Batch (None, 256, 256, 32) 128         conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 256, 256, 32) 0           batch_normalization_v1_1[0][0]   \n","__________________________________________________________________________________________________\n","max_pooling2d (MaxPooling2D)    (None, 128, 128, 32) 0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 128, 128, 64) 18496       max_pooling2d[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_v1_2 (Batch (None, 128, 128, 64) 256         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 128, 128, 64) 0           batch_normalization_v1_2[0][0]   \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 128, 128, 64) 36928       activation_2[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_v1_3 (Batch (None, 128, 128, 64) 256         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 128, 128, 64) 0           batch_normalization_v1_3[0][0]   \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 64)   0           activation_3[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 64, 64, 128)  73856       max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_v1_4 (Batch (None, 64, 64, 128)  512         conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 64, 64, 128)  0           batch_normalization_v1_4[0][0]   \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 64, 64, 128)  147584      activation_4[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_v1_5 (Batch (None, 64, 64, 128)  512         conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 64, 64, 128)  0           batch_normalization_v1_5[0][0]   \n","__________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 128)  0           activation_5[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 32, 32, 256)  295168      max_pooling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_v1_6 (Batch (None, 32, 32, 256)  1024        conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 32, 32, 256)  0           batch_normalization_v1_6[0][0]   \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 32, 32, 256)  590080      activation_6[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_v1_7 (Batch (None, 32, 32, 256)  1024        conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 32, 32, 256)  0           batch_normalization_v1_7[0][0]   \n","__________________________________________________________________________________________________\n","max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 256)  0           activation_7[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 16, 16, 512)  1180160     max_pooling2d_3[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_v1_8 (Batch (None, 16, 16, 512)  2048        conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 16, 16, 512)  0           batch_normalization_v1_8[0][0]   \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 16, 16, 512)  2359808     activation_8[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_v1_9 (Batch (None, 16, 16, 512)  2048        conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 16, 16, 512)  0           batch_normalization_v1_9[0][0]   \n","__________________________________________________________________________________________________\n","max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 512)    0           activation_9[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 8, 8, 1024)   4719616     max_pooling2d_4[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_v1_10 (Batc (None, 8, 8, 1024)   4096        conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 8, 8, 1024)   0           batch_normalization_v1_10[0][0]  \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 8, 8, 1024)   9438208     activation_10[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_v1_11 (Batc (None, 8, 8, 1024)   4096        conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 8, 8, 1024)   0           batch_normalization_v1_11[0][0]  \n","__________________________________________________________________________________________________\n","conv2d_transpose (Conv2DTranspo (None, 16, 16, 512)  2097664     activation_11[0][0]              \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 16, 16, 1024) 0           activation_9[0][0]               \n","                                                                 conv2d_transpose[0][0]           \n","__________________________________________________________________________________________________\n","batch_normalization_v1_12 (Batc (None, 16, 16, 1024) 4096        concatenate[0][0]                \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 16, 16, 1024) 0           batch_normalization_v1_12[0][0]  \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 16, 16, 512)  4719104     activation_12[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_v1_13 (Batc (None, 16, 16, 512)  2048        conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 16, 16, 512)  0           batch_normalization_v1_13[0][0]  \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 16, 16, 512)  2359808     activation_13[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_v1_14 (Batc (None, 16, 16, 512)  2048        conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 16, 16, 512)  0           batch_normalization_v1_14[0][0]  \n","__________________________________________________________________________________________________\n","conv2d_transpose_1 (Conv2DTrans (None, 32, 32, 256)  524544      activation_14[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 32, 32, 512)  0           activation_7[0][0]               \n","                                                                 conv2d_transpose_1[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_v1_15 (Batc (None, 32, 32, 512)  2048        concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 32, 32, 512)  0           batch_normalization_v1_15[0][0]  \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 32, 32, 256)  1179904     activation_15[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_v1_16 (Batc (None, 32, 32, 256)  1024        conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 32, 32, 256)  0           batch_normalization_v1_16[0][0]  \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 32, 32, 256)  590080      activation_16[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_v1_17 (Batc (None, 32, 32, 256)  1024        conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 32, 32, 256)  0           batch_normalization_v1_17[0][0]  \n","__________________________________________________________________________________________________\n","conv2d_transpose_2 (Conv2DTrans (None, 64, 64, 128)  131200      activation_17[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 64, 64, 256)  0           activation_5[0][0]               \n","                                                                 conv2d_transpose_2[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_v1_18 (Batc (None, 64, 64, 256)  1024        concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 64, 64, 256)  0           batch_normalization_v1_18[0][0]  \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 64, 64, 128)  295040      activation_18[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_v1_19 (Batc (None, 64, 64, 128)  512         conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 64, 64, 128)  0           batch_normalization_v1_19[0][0]  \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 64, 64, 128)  147584      activation_19[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_v1_20 (Batc (None, 64, 64, 128)  512         conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 64, 64, 128)  0           batch_normalization_v1_20[0][0]  \n","__________________________________________________________________________________________________\n","conv2d_transpose_3 (Conv2DTrans (None, 128, 128, 64) 32832       activation_20[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_3 (Concatenate)     (None, 128, 128, 128 0           activation_3[0][0]               \n","                                                                 conv2d_transpose_3[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_v1_21 (Batc (None, 128, 128, 128 512         concatenate_3[0][0]              \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 128, 128, 128 0           batch_normalization_v1_21[0][0]  \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 128, 128, 64) 73792       activation_21[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_v1_22 (Batc (None, 128, 128, 64) 256         conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 128, 128, 64) 0           batch_normalization_v1_22[0][0]  \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 128, 128, 64) 36928       activation_22[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_v1_23 (Batc (None, 128, 128, 64) 256         conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 128, 128, 64) 0           batch_normalization_v1_23[0][0]  \n","__________________________________________________________________________________________________\n","conv2d_transpose_4 (Conv2DTrans (None, 256, 256, 32) 8224        activation_23[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_4 (Concatenate)     (None, 256, 256, 64) 0           activation_1[0][0]               \n","                                                                 conv2d_transpose_4[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_v1_24 (Batc (None, 256, 256, 64) 256         concatenate_4[0][0]              \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 256, 256, 64) 0           batch_normalization_v1_24[0][0]  \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 256, 256, 32) 18464       activation_24[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_v1_25 (Batc (None, 256, 256, 32) 128         conv2d_20[0][0]                  \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 256, 256, 32) 0           batch_normalization_v1_25[0][0]  \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 256, 256, 32) 9248        activation_25[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_v1_26 (Batc (None, 256, 256, 32) 128         conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","activation_26 (Activation)      (None, 256, 256, 32) 0           batch_normalization_v1_26[0][0]  \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 256, 256, 8)  264         activation_26[0][0]              \n","==================================================================================================\n","Total params: 31,126,152\n","Trainable params: 31,110,152\n","Non-trainable params: 16,000\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"0QZLubQvGSRR","colab_type":"code","colab":{}},"cell_type":"code","source":["save_model_path = '/content/gdrive/My Drive/DeepLearning/2DUNet/Logs/weights_multi-all-coronal.hdf5'\n","cp = tf.keras.callbacks.ModelCheckpoint(filepath=save_model_path, monitor='val_dice_loss', save_best_only=True, verbose=1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TZO8_imZc-16","colab_type":"code","outputId":"fcd6fbf9-ab64-4b9c-de16-0d72eee3bd87","executionInfo":{"status":"ok","timestamp":1553707876467,"user_tz":420,"elapsed":26090,"user":{"displayName":"Fanwei Kong","photoUrl":"","userId":"05426665111850906095"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"cell_type":"code","source":["# Alternatively, load the weights directly: model.load_weights(save_model_path)\n","try:\n","  model = models.load_model(save_model_path, custom_objects={'bce_dice_loss': bce_dice_loss, 'dice_loss': dice_loss})\n","except:\n","  print(\"model not loaded\")\n","  pass"],"execution_count":38,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Deprecated in favor of operator or tf.math.divide.\n"],"name":"stdout"}]},{"metadata":{"id":"6vrtUW075EIJ","colab_type":"text"},"cell_type":"markdown","source":[""]},{"metadata":{"id":"Ha0xjYcRGT4I","colab_type":"code","outputId":"eb1e2963-ea12-4883-cf82-72370987e3dd","colab":{"base_uri":"https://localhost:8080/","height":1023}},"cell_type":"code","source":["history = model.fit(train_ds, \n","                   steps_per_epoch=int(np.ceil(num_train_examples / float(batch_size))),\n","                   epochs=epochs,\n","                   validation_data=val_ds,\n","                   validation_steps=int(np.ceil(num_val_examples / float(batch_size))),\n","                   callbacks=[cp])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/300\n","1736/1737 [============================>.] - ETA: 0s - loss: 26.0412 - dice_loss: 2.8512\n","Epoch 00001: val_dice_loss improved from inf to 1.99270, saving model to /content/gdrive/My Drive/DeepLearning/2DUNet/Logs/weights_multi-all-coronal.hdf5\n","1737/1737 [==============================] - 1423s 819ms/step - loss: 26.0366 - dice_loss: 2.8505 - val_loss: 17.8034 - val_dice_loss: 1.9927\n","Epoch 2/300\n","1736/1737 [============================>.] - ETA: 0s - loss: 18.9430 - dice_loss: 2.1088\n","Epoch 00002: val_dice_loss improved from 1.99270 to 1.59678, saving model to /content/gdrive/My Drive/DeepLearning/2DUNet/Logs/weights_multi-all-coronal.hdf5\n","1737/1737 [==============================] - 1214s 699ms/step - loss: 18.9457 - dice_loss: 2.1091 - val_loss: 14.4929 - val_dice_loss: 1.5968\n","Epoch 3/300\n","1736/1737 [============================>.] - ETA: 0s - loss: 15.8788 - dice_loss: 1.7781\n","Epoch 00003: val_dice_loss did not improve from 1.59678\n","1737/1737 [==============================] - 1208s 695ms/step - loss: 15.8809 - dice_loss: 1.7784 - val_loss: 37.8794 - val_dice_loss: 4.0276\n","Epoch 4/300\n","1736/1737 [============================>.] - ETA: 0s - loss: 15.8435 - dice_loss: 1.7743\n","Epoch 00004: val_dice_loss improved from 1.59678 to 1.45218, saving model to /content/gdrive/My Drive/DeepLearning/2DUNet/Logs/weights_multi-all-coronal.hdf5\n","1737/1737 [==============================] - 1220s 702ms/step - loss: 15.8406 - dice_loss: 1.7739 - val_loss: 12.9321 - val_dice_loss: 1.4522\n","Epoch 5/300\n","1736/1737 [============================>.] - ETA: 0s - loss: 14.7954 - dice_loss: 1.6569\n","Epoch 00005: val_dice_loss did not improve from 1.45218\n","1737/1737 [==============================] - 1216s 700ms/step - loss: 14.7946 - dice_loss: 1.6567 - val_loss: 13.2977 - val_dice_loss: 1.4880\n","Epoch 6/300\n","1736/1737 [============================>.] - ETA: 0s - loss: 14.3930 - dice_loss: 1.6127\n","Epoch 00006: val_dice_loss did not improve from 1.45218\n","1737/1737 [==============================] - 1217s 701ms/step - loss: 14.3923 - dice_loss: 1.6127 - val_loss: 14.2854 - val_dice_loss: 1.6016\n","Epoch 7/300\n","1736/1737 [============================>.] - ETA: 0s - loss: 14.4426 - dice_loss: 1.6215\n","Epoch 00007: val_dice_loss improved from 1.45218 to 1.38524, saving model to /content/gdrive/My Drive/DeepLearning/2DUNet/Logs/weights_multi-all-coronal.hdf5\n","1737/1737 [==============================] - 1226s 706ms/step - loss: 14.4401 - dice_loss: 1.6212 - val_loss: 12.3329 - val_dice_loss: 1.3852\n","Epoch 8/300\n","1736/1737 [============================>.] - ETA: 0s - loss: 14.0138 - dice_loss: 1.5741\n","Epoch 00008: val_dice_loss improved from 1.38524 to 1.37358, saving model to /content/gdrive/My Drive/DeepLearning/2DUNet/Logs/weights_multi-all-coronal.hdf5\n","1737/1737 [==============================] - 1219s 702ms/step - loss: 14.0098 - dice_loss: 1.5736 - val_loss: 12.0993 - val_dice_loss: 1.3736\n","Epoch 9/300\n","1736/1737 [============================>.] - ETA: 0s - loss: 13.0322 - dice_loss: 1.4684\n","Epoch 00009: val_dice_loss did not improve from 1.37358\n","1737/1737 [==============================] - 1212s 698ms/step - loss: 13.0321 - dice_loss: 1.4684 - val_loss: 20.7602 - val_dice_loss: 2.2192\n","Epoch 10/300\n","1736/1737 [============================>.] - ETA: 0s - loss: 13.4931 - dice_loss: 1.5093\n","Epoch 00010: val_dice_loss improved from 1.37358 to 1.26913, saving model to /content/gdrive/My Drive/DeepLearning/2DUNet/Logs/weights_multi-all-coronal.hdf5\n","1737/1737 [==============================] - 1219s 702ms/step - loss: 13.4884 - dice_loss: 1.5088 - val_loss: 11.1869 - val_dice_loss: 1.2691\n","Epoch 11/300\n","1736/1737 [============================>.] - ETA: 0s - loss: 12.8508 - dice_loss: 1.4427\n","Epoch 00011: val_dice_loss improved from 1.26913 to 1.23492, saving model to /content/gdrive/My Drive/DeepLearning/2DUNet/Logs/weights_multi-all-coronal.hdf5\n","1737/1737 [==============================] - 1215s 700ms/step - loss: 12.8542 - dice_loss: 1.4432 - val_loss: 10.9736 - val_dice_loss: 1.2349\n","Epoch 12/300\n","1736/1737 [============================>.] - ETA: 0s - loss: 13.1749 - dice_loss: 1.4834\n","Epoch 00012: val_dice_loss did not improve from 1.23492\n","1737/1737 [==============================] - 1203s 692ms/step - loss: 13.1740 - dice_loss: 1.4832 - val_loss: 18.1040 - val_dice_loss: 2.0173\n","Epoch 13/300\n","1736/1737 [============================>.] - ETA: 0s - loss: 12.2666 - dice_loss: 1.3823\n","Epoch 00013: val_dice_loss did not improve from 1.23492\n","1737/1737 [==============================] - 1203s 693ms/step - loss: 12.2736 - dice_loss: 1.3831 - val_loss: 14.0190 - val_dice_loss: 1.5787\n","Epoch 14/300\n","1736/1737 [============================>.] - ETA: 0s - loss: 11.7381 - dice_loss: 1.3289\n","Epoch 00014: val_dice_loss did not improve from 1.23492\n","1737/1737 [==============================] - 1206s 694ms/step - loss: 11.7348 - dice_loss: 1.3285 - val_loss: 21.2525 - val_dice_loss: 2.3856\n","Epoch 15/300\n","1201/1737 [===================>..........] - ETA: 5:44 - loss: 11.5468 - dice_loss: 1.3082"],"name":"stdout"}]},{"metadata":{"id":"STD8wNqHckir","colab_type":"code","colab":{}},"cell_type":"code","source":["dice = history.history['dice_loss']\n","val_dice = history.history['val_dice_loss']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs_range = range(epochs)\n","\n","plt.figure(figsize=(16, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, dice, label='Training Dice Loss')\n","plt.plot(epochs_range, val_dice, label='Validation Dice Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Dice Loss')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Gn6qbeLedBh3","colab_type":"code","colab":{}},"cell_type":"code","source":["# Let's visualize some of the outputs \n","data_aug_iter = val_ds.make_one_shot_iterator()\n","next_element = data_aug_iter.get_next()\n","\n","batch_of_imgs, label = tf.keras.backend.get_session().run(next_element)\n","predicted_label = np.argmax(model.predict(batch_of_imgs),axis=-1)\n","# Running next element in our graph will produce a batch of images\n","plt.figure(figsize=(10, 20))\n","for i in range(5):\n","  img = batch_of_imgs[i]\n","  print(np.unique(label[i]))\n","  print(np.unique(predicted_label[i]))\n","  plt.subplot(5, 3, 3 * i + 1)\n","  plt.imshow(img[:,:,0])\n","  plt.title(\"Input image\")\n","  \n","  plt.subplot(5, 3, 3 * i + 2)\n","  plt.imshow(label[i, :, :, 0])\n","  plt.title(\"Actual Mask\")\n","  plt.subplot(5, 3, 3 * i + 3)\n","  plt.imshow(predicted_label[i, :, :])\n","  plt.title(\"Predicted Mask\")\n","plt.suptitle(\"Examples of Input Image, Label, and Prediction\")\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"85-0-AKQUnFC","colab_type":"code","colab":{}},"cell_type":"code","source":["debug_label = model.predict(batch_of_imgs)\n","debug_label_bk = debug_label[2,:,:,0]\n","debug_label_la = debug_label[2,:,:,2]\n","print(debug_label_bk.shape)\n","print(debug_label_la.shape)\n","plt.subplot(1,2,1)\n","plt.imshow(debug_label_bk)\n","plt.subplot(1,2,2)\n","plt.imshow(debug_label_la)\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"n_-9987-f386","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}