# -*- coding: utf-8 -*-
"""2dUNet_multiclass.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1N0myNq6nWUycyo0zTBRmLgD-0Kjbeoxd
"""
import os
import glob
import functools

import numpy as np
import matplotlib.pyplot as plt
import matplotlib as mpl
mpl.rcParams['axes.grid'] = False
mpl.rcParams['figure.figsize'] = (12,12)

from sklearn.model_selection import train_test_split
import matplotlib.image as mpimg
import pandas as pd
from PIL import Image

import tensorflow as tf
import tensorflow.contrib as tfcontrib
from tensorflow.python.keras import layers
from tensorflow.python.keras import losses
from tensorflow.python.keras import models
from tensorflow.python.keras import backend as K

import h5py
import SimpleITK as sitk

"""# Set up"""

img_shape = (256, 256, 1)
num_class = 8
batch_size = 10
epochs = 100

modality = ["ct", "mr"]
im_base_name = 'MMWHS_small'
base_name = 'MMWHS_small_btstrp3'
data_folder = '/global/scratch/fanwei_kong/ImageData/%s' % im_base_name
view = 0
seed = 41
view_names = ['axial', 'coronal', 'sagittal']
data_folder_out = '/global/scratch/fanwei_kong/ImageData/%s/2d_multiclass-%s2' % (im_base_name,view_names[view])
save_model_path = '/global/scratch/fanwei_kong/2DUNet/Logs/%s/weights_multi-all-%s_small2.hdf5' % (base_name,view_names[view])
save_loss_path = '/global/scratch/fanwei_kong/2DUNet/Logs/%s/%s' % (base_name,view_names[view])
overwrite = False

try:
    os.mkdir(os.path.dirname(save_model_path))
    os.mkdir(os.oath.dirname(save_loss_path))
except Exception as e: print(e)




"""Find training data filenames and label filenames"""

def getTrainNLabelNames(data_folder, m, ext='*.nii.gz'):
  x_train_filenames = []
  y_train_filenames = []
  for subject_dir in sorted(glob.glob(os.path.join(data_folder,m+'_train',ext))):
      x_train_filenames.append(os.path.realpath(subject_dir))
  for subject_dir in sorted(glob.glob(os.path.join(data_folder ,m+'_train_masks',ext))):
      y_train_filenames.append(os.path.realpath(subject_dir))
  return x_train_filenames, y_train_filenames

"""Convert 3D data to 2D data"""

def swapLabels(labels):
    labels[labels==421]=420
    unique_label = np.unique(labels)

    new_label = range(len(unique_label))
    for i in range(len(unique_label)):
        label = unique_label[i]
        print(label)
        newl = new_label[i]
        print(newl)
        labels[labels==label] = newl
       
    print(unique_label)

    return labels

def RescaleIntensity(slice_im,m):
  #slice_im: numpy array
  #m: modality, ct or mr
  if m =="ct":
    slice_im[slice_im>750] = 750
    slice_im[slice_im<-750] = -750
    slice_im = slice_im/750
  elif m=="mr":
#     top_10 = np.percentile(slice_im,90)
#     above = slice_im[slice_im>top_10]
#     med = np.median(above)
#     slice_im = slice_im/med
#     slice_im[slice_im>1.] = 1.
#     slice_im = slice_im*2.-1.
    slice_im[slice_im>1500] = 1500
    slice_im = (slice_im-750)/750
  return slice_im

def np_to_tfrecords(X, Y, file_path_prefix, verbose=True):
    def _bytes_feature(value):
      """Returns a bytes_list from a string / byte."""
      return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))

    def _float_feature(value):
      """Returns a float_list from a float / double."""
      return tf.train.Feature(float_list=tf.train.FloatList(value=value))

    def _int64_feature(value):
      """Returns an int64_list from a bool / enum / int / uint."""
      return tf.train.Feature(int64_list=tf.train.Int64List(value=value))
            
    if Y is not None:
        assert X.shape == Y.shape
    
    # Generate tfrecord writer
    result_tf_file = file_path_prefix + '.tfrecords'
    writer = tf.python_io.TFRecordWriter(result_tf_file)
    if verbose:
        print("Serializing example into {}".format(result_tf_file))
        
    # iterate over each sample,
    # and serialize it as ProtoBuf.
    
    d_feature = {}
    d_feature['X'] = _float_feature(X.flatten())
    if Y is not None:
        d_feature['Y'] = _int64_feature(Y.flatten())
    d_feature['shape0'] = _int64_feature([X.shape[0]])
    d_feature['shape1'] = _int64_feature([X.shape[1]])
            
    features = tf.train.Features(feature=d_feature)
    example = tf.train.Example(features=features)
    serialized = example.SerializeToString()
    writer.write(serialized)
    
    if verbose:
        print("Writing {} done!".format(result_tf_file))

def data_preprocess(modality,data_folder,view, data_folder_out):
  train_img_path = []
  train_mask_path = []
  train_weights = []
  for m in modality:
    imgVol_fn, mask_fn = getTrainNLabelNames(data_folder, m)
    print("number of training data %d" % len(imgVol_fn))
    assert len(imgVol_fn) == len(mask_fn)

    for i in range(0,len(imgVol_fn)):
      img_path = imgVol_fn[i]
      mask_path = mask_fn[i]
      imgVol = sitk.GetArrayFromImage(sitk.ReadImage(img_path))  # numpy array
      imgVol = RescaleIntensity(imgVol, m)
      #imgVol = HistogramEqualization(imgVol)
      maskVol = sitk.GetArrayFromImage(sitk.ReadImage(mask_path))  # numpy array
      maskVol = swapLabels(maskVol)
      if m =="mr":
        imgVol = np.moveaxis(imgVol,0,-1)
        maskVol = np.moveaxis(maskVol,0,-1)
      print("number of image slices in this view %d" % imgVol.shape[view])
      #remove the blank images with a probability - find the index first
      IDs = np.max(maskVol,axis=view)==0
      
      for sid in range(imgVol.shape[view]):
        if IDs[sid] and np.random.rand(1)>0.2:
            continue
        out_im_path = os.path.join(data_folder_out, m+'_train', m+'_train'+str(i)+'_'+str(sid))
        out_msk_path = os.path.join(data_folder_out, m+'_train_masks',  m+'_train_mask'+str(i)+'_'+str(sid))
        slice_im = np.moveaxis(imgVol,view,0)[sid,:,:]
        slice_msk = np.moveaxis(maskVol,view,0)[sid,:,:]
        np_to_tfrecords(slice_im.astype(np.float32),slice_msk.astype(np.int64), out_im_path, verbose=True)
        train_img_path.append(out_im_path)
        train_mask_path.append(out_msk_path)
  return train_img_path, train_mask_path

def sample(iterable, n):
    """
    Returns @param n random items from @param iterable.
    """
    if n == 0:
      return []
    reservoir = []
    factor = int(np.ceil(float(n)/float(len(iterable))))
    for i in range(0,factor-1):
      iterable+=iterable
    for t, item in enumerate(iterable):
        if t < n:
            reservoir.append(item)
        else:
            m = np.random.randint(0,t)
            if m < n:
                reservoir[m] = item
    return reservoir

def bootstrapping(fn_names):
    index = np.array(range(len(fn_names)))
    new_fn_names = [None]*len(fn_names)
    for i in range(len(fn_names)):
        new_fn_names[i] = fn_names[int(np.random.choice(index,replace=True))]

    return new_fn_names

print("Making dir...")
try:
  os.mkdir(data_folder_out)
except Exception as e: print(e)
for m in modality:
  try:
    os.mkdir(os.path.join(data_folder_out, m+'_train'))
    #os.mkdir(os.path.join(data_folder_out, m+'_train_masks'))
  except Exception as e: print(e)

if overwrite:
  _, _  = data_preprocess(modality,data_folder,view, data_folder_out)

x_train_filenames = []
filenames = [None]*len(modality)
nums = np.zeros(len(modality))
for i, m in enumerate(modality):
  filenames[i], _ = getTrainNLabelNames(data_folder_out, m, ext='*.tfrecords')
  nums[i] = len(filenames[i])
  x_train_filenames+=filenames[i]
  print(nums)
  
np.random.seed(seed)
nums = np.max(nums) - nums
for i , _ in enumerate(modality):
  index = sample(list(range(len(filenames[i]))), nums[i])
  x_train_filenames+=[filenames[i][j] for j in index]

  
x_train_filenames, x_val_filenames = train_test_split(x_train_filenames, test_size=0.2, random_state=seed)
x_train_filenames = bootstrapping(x_train_filenames)

num_train_examples = len(x_train_filenames)
num_val_examples = len(x_val_filenames)

print("Number of training examples: {}".format(num_train_examples))
print("Number of validation examples: {}".format(num_val_examples))


"""# Build our input pipeline with `tf.data`

## Shifting the image
"""

def shift_img(output_img, label_img, width_shift_range, height_shift_range):
  """This fn will perform the horizontal or vertical shift"""
  if width_shift_range or height_shift_range:
      if width_shift_range:
        width_shift_range = tf.random_uniform([], 
                                              -width_shift_range * img_shape[1],
                                              width_shift_range * img_shape[1])
      if height_shift_range:
        height_shift_range = tf.random_uniform([],
                                               -height_shift_range * img_shape[0],
                                               height_shift_range * img_shape[0])
      # Translate both 
      output_img = tfcontrib.image.translate(output_img,
                                             [width_shift_range, height_shift_range])
      label_img = tfcontrib.image.translate(label_img,
                                             [width_shift_range, height_shift_range])
  return output_img, label_img

"""## Flipping the image randomly"""

def flip_img(horizontal_flip, tr_img, label_img):
  if horizontal_flip:
    flip_prob = tf.random_uniform([], 0.0, 1.0)
    tr_img, label_img = tf.cond(tf.less(flip_prob, 0.5),
                                lambda: (tf.image.flip_left_right(tr_img), tf.image.flip_left_right(label_img)),
                                lambda: (tr_img, label_img))
  return tr_img, label_img

"""##Scale/shift the image intensity randomly"""

def changeIntensity_img(tr_img, label_img, changeIntensity=False):
  if changeIntensity:
    scale = tf.random_uniform([], 0.9, 1.1)
    shift = tf.random_uniform([], -0.1, 0.1)
    tr_img = tr_img*scale+shift
    
  return tr_img, label_img

"""## Assembling our transformations into our augment function"""

def _augment(img,
             label_img,
             resize=None,  # Resize the image to some size e.g. [256, 256]
             horizontal_flip=False,  # Random left right flip,
             changeIntensity=False,
             width_shift_range=0,  # Randomly translate the image horizontally
             height_shift_range=0):  # Randomly translate the image vertically 
  if resize is not None:
    # Resize both images
    label_img = tf.image.resize_images(label_img, resize, method=tf.image.ResizeMethod.NEAREST_NEIGHBOR, align_corners=True)
    img = tf.image.resize_images(img, resize, method=tf.image.ResizeMethod.NEAREST_NEIGHBOR, align_corners=True)
  
  
  img, label_img = flip_img(horizontal_flip, img, label_img)
  img, label_img = shift_img(img, label_img, width_shift_range, height_shift_range)
  img, label_img = changeIntensity_img(img, label_img,changeIntensity )
  return img, label_img

"""## Processing each pathname"""

def _parse_function(example_proto):
  features = {"X": tf.VarLenFeature(tf.float32),
              "Y": tf.VarLenFeature(tf.int64),
              "shape0": tf.FixedLenFeature((), tf.int64),
              "shape1": tf.FixedLenFeature((), tf.int64)}
  parsed_features = tf.parse_single_example(example_proto, features)
  img = tf.sparse_tensor_to_dense(parsed_features["X"])
  height = tf.cast(parsed_features["shape0"], tf.int32)
  width = tf.cast(parsed_features["shape1"], tf.int32)
  print(img,parsed_features)
  label = tf.sparse_tensor_to_dense(parsed_features["Y"])
  img = tf.reshape(img, tf.stack([height, width,1]))
  label = tf.reshape(label, tf.stack([height, width,1]) )
  label = tf.cast(label, tf.int32)
  return img, label

def _process_pathnames(fname):
  # We map this function onto each pathname pair  
  dataset_str = tf.read_file(fname)
  dataset = tf.data.TFRecordDataset(dataset_str)
  parsed_features = dataset.map(_parse_function)
  
  iterator = dataset.make_one_shot_iterator()
  #data = iterator.get_next()
  
  img = tf.sparse_tensor_to_dense(parsed_features["X"])
  height = tf.cast(parsed_features["shape0"], tf.int32)
  width = tf.cast(parsed_features["shape1"], tf.int32)
  label = tf.sparse_tensor_to_dense(parsed_features["Y"])
  img = tf.reshape(img, tf.stack([height, width]))
  label = tf.reshape(label, tf.stack([height, width]) )

  print(img, label)
  return img, label

"""##Assemble Dataset"""

def get_baseline_dataset(filenames, preproc_fn=functools.partial(_augment),
                         threads=5, 
                         batch_size=batch_size,
                         shuffle=True):           
  num_x = len(filenames)
  # Create a dataset from the filenames and labels
  files = tf.data.Dataset.from_tensor_slices(filenames)
  print(files)
  
  dataset = files.apply(tf.contrib.data.parallel_interleave(
    tf.data.TFRecordDataset, cycle_length=threads))
  # Map our preprocessing function to every element in our dataset, taking
  # advantage of multithreading
  dataset = dataset.map(_parse_function, num_parallel_calls=threads)
  # dataset = dataset.map(_process_pathnames, num_parallel_calls=threads)
  if preproc_fn.keywords is not None and 'resize' not in preproc_fn.keywords:
    assert batch_size == 1, "Batching images must be of the same size"

  dataset = dataset.map(preproc_fn, num_parallel_calls=threads)
  print(num_x)
  if shuffle:
    dataset = dataset.shuffle(6000)
  
  
  # It's necessary to repeat our data for all epochs 
  dataset = dataset.repeat().batch(batch_size)
  dataset = dataset.prefetch(buffer_size=batch_size)

  return dataset

"""## Set up train and validation datasets
Note that we apply image augmentation to our training dataset but not our validation dataset.
"""

tr_cfg = {
    'resize': [img_shape[0], img_shape[1]],
    'horizontal_flip': True,
    'changeIntensity': True,
    'width_shift_range': 0.1,
    'height_shift_range': 0.1
}
tr_preprocessing_fn = functools.partial(_augment, **tr_cfg)

val_cfg = {
    'resize': [img_shape[0], img_shape[1]],
}
val_preprocessing_fn = functools.partial(_augment, **val_cfg)

train_ds = get_baseline_dataset(x_train_filenames, preproc_fn=tr_preprocessing_fn,
                                batch_size=batch_size)
val_ds = get_baseline_dataset(x_train_filenames, preproc_fn=val_preprocessing_fn,
                              batch_size=batch_size)


"""# Build the model"""

def conv_block(input_tensor, num_filters):
  encoder = layers.Conv2D(num_filters, (3, 3), padding='same')(input_tensor)
  encoder = layers.BatchNormalization()(encoder)
  encoder = layers.Activation('relu')(encoder)
  encoder = layers.Conv2D(num_filters, (3, 3), padding='same')(encoder)
  encoder = layers.BatchNormalization()(encoder)
  encoder = layers.Activation('relu')(encoder)
  return encoder

def encoder_block(input_tensor, num_filters):
  encoder = conv_block(input_tensor, num_filters)
  encoder_pool = layers.MaxPooling2D((2, 2), strides=(2, 2))(encoder)
  
  return encoder_pool, encoder

def decoder_block(input_tensor, concat_tensor, num_filters):
  decoder = layers.Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(input_tensor)
  decoder = layers.concatenate([concat_tensor, decoder], axis=-1)
  decoder = layers.BatchNormalization()(decoder)
  decoder = layers.Activation('relu')(decoder)
  decoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)
  decoder = layers.BatchNormalization()(decoder)
  decoder = layers.Activation('relu')(decoder)
  decoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)
  decoder = layers.BatchNormalization()(decoder)
  decoder = layers.Activation('relu')(decoder)
  return decoder

inputs = layers.Input(shape=img_shape)
# 256

encoder0_pool, encoder0 = encoder_block(inputs, 32)
# 128

encoder1_pool, encoder1 = encoder_block(encoder0_pool, 64)
# 64

encoder2_pool, encoder2 = encoder_block(encoder1_pool, 128)
# 32

encoder3_pool, encoder3 = encoder_block(encoder2_pool, 256)
# 16

encoder4_pool, encoder4 = encoder_block(encoder3_pool, 512)
# 8

center = conv_block(encoder4_pool, 1024)
# center

decoder4 = decoder_block(center, encoder4, 512)
# 16

decoder3 = decoder_block(decoder4, encoder3, 256)
# 32

decoder2 = decoder_block(decoder3, encoder2, 128)
# 64

decoder1 = decoder_block(decoder2, encoder1, 64)
# 128

decoder0 = decoder_block(decoder1, encoder0, 32)
# 256

outputs = layers.Conv2D(num_class, (1, 1), activation='softmax', data_format="channels_last")(decoder0)

model = models.Model(inputs=[inputs], outputs=[outputs])

def dice_coeff(y_true, y_pred):
    smooth = 1.
    # Flatten
    y_true_f = tf.reshape(y_true, [-1])
    y_pred_f = tf.reshape(y_pred, [-1])
    intersection = tf.reduce_sum(y_true_f * y_pred_f)
    score = (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)
    return score

from tensorflow.python.keras.utils import to_categorical
def dice_loss(y_true, y_pred):
    y_true_one_hot = tf.one_hot(tf.cast(y_true,tf.int32), num_class)
    loss = 0.
    weights = [1.,1.,1.,1.,1.,1.,1.,1.]
    for i in range(num_class):
      loss += weights[i]*(1 - dice_coeff(y_true_one_hot[:,:,:,:,i], y_pred[:,:,:,i]))
    return loss

def bce_dice_loss(y_true, y_pred):
    loss = losses.sparse_categorical_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)
    return loss

def la_loss(y_true, y_pred):
    y_true_one_hot = tf.one_hot(tf.cast(y_true,tf.int32), num_class)
    loss = 1 - dice_coeff(y_true_one_hot[:,:,:,:,2], y_pred[:,:,:,2])
    return loss

from tensorflow.python.keras.optimizers import Adam
adam = Adam(lr=0.02, beta_1=0.9, beta_2=0.999, epsilon=None, decay=1e-6, amsgrad=False)
model.compile(optimizer=adam, loss=bce_dice_loss, metrics=[dice_loss])

model.summary()

cp = tf.keras.callbacks.ModelCheckpoint(filepath=save_model_path, monitor='val_dice_loss', save_best_only=True, verbose=1)

# Alternatively, load the weights directly: model.load_weights(save_model_path)
try:
  model = models.load_model(save_model_path, custom_objects={'bce_dice_loss': bce_dice_loss, 'dice_loss': dice_loss})
except:
  print("model not loaded")
  pass

history = model.fit(train_ds, 
                   steps_per_epoch=int(np.ceil(num_train_examples / float(batch_size))),
                   epochs=epochs,
                   validation_data=val_ds,
                   validation_steps=int(np.ceil(num_val_examples / float(batch_size))),
                   callbacks=[cp])

from pickle import dump
with open(save_loss_path+"history", 'wb') as handle: # saving the history 
        dump(history.history, handle)

