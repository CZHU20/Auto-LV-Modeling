{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"JrTI6JuPcvqM","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"D6nh4fNjc3AC","colab_type":"code","outputId":"84068a5f-eb0d-47c6-a788-292fe511b90b","executionInfo":{"status":"ok","timestamp":1556060818431,"user_tz":420,"elapsed":286,"user":{"displayName":"Fanwei Kong","photoUrl":"","userId":"05426665111850906095"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd '/content/gdrive/My Drive/DeepLearning/2DUnet-git'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/DeepLearning/2DUnet-git\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GSmSuOmWXk2s","colab_type":"code","outputId":"a7c6f019-44dd-4caf-95ad-84db6b32e40e","executionInfo":{"status":"error","timestamp":1556061667943,"user_tz":420,"elapsed":497,"user":{"displayName":"Fanwei Kong","photoUrl":"","userId":"05426665111850906095"}},"colab":{"base_uri":"https://localhost:8080/","height":215}},"source":["from __future__ import print_function, division\n","import scipy\n","\n","from keras.datasets import mnist\n","from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n","from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.layers.convolutional import UpSampling2D, Conv2D\n","from keras.models import Sequential, Model\n","from keras.optimizers import Adam\n","from model import UNet2D\n","from loss import bce_dice_loss\n","import datetime\n","import matplotlib.pyplot as plt\n","import sys\n","import numpy as np\n","import os\n","\n","class DANet():\n","    def __init__(self, dataset):\n","        # Input shape\n","        self.img_rows = 256\n","        self.img_cols = 256\n","        self.channels = 1\n","        self.num_class = 8\n","        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n","\n","        # Configure data loader\n","        self.dataset_name = 'facades'\n","        self.data_loader = dataset\n","\n","\n","        # Calculate output shape of D (PatchGAN)\n","        patch = int(self.img_rows / 2**4)\n","        self.disc_patch = (patch, patch, 1)\n","\n","        # Number of filters in the first layer D\n","        self.df = 64\n","\n","        optimizer = Adam(0.0002, 0.5)\n","\n","        # Build and compile the discriminator\n","        self.discriminator = self.build_discriminator()\n","        self.discriminator.compile(loss='mse',\n","            optimizer=optimizer,\n","            metrics=['accuracy'])\n","\n","        #-------------------------\n","        # Construct Computational\n","        #   Graph of Generator\n","        #-------------------------\n","\n","        # Build the generator\n","        self.generator = self.build_generator()\n","\n","        # Input images and their conditioning images\n","        img_A = Input(shape=self.img_shape)\n","        img_B = Input(shape=self.img_shape)\n","\n","        # By conditioning on B generate a fake version of A\n","        fake_A = self.generator(img_B)\n","\n","        # For the combined model we will only train the generator\n","        self.discriminator.trainable = False\n","\n","        # Discriminators determines validity of translated images / condition pairs\n","        valid = self.discriminator([fake_A, img_B])\n","\n","        self.combined = Model(inputs=[img_A, img_B], outputs=[valid, fake_A])\n","        self.combined.compile(loss=['mse', bce_dice_loss],\n","                              loss_weights=[1, 100],\n","                              optimizer=optimizer)\n","\n","    def build_generator(self):\n","        \"\"\"U-Net Generator\"\"\"\n","\n","        UNet2D(img_shape,num_class)\n","        \n","        inputs, outputs = UNet2D(self.img_shape, self.num_class)\n","\n","        return Model(inputs=[inputs], outputs=[outputs])\n","\n","    def build_discriminator(self):\n","\n","        def d_layer(layer_input, filters, f_size=4, bn=True):\n","            \"\"\"Discriminator layer\"\"\"\n","            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n","            d = LeakyReLU(alpha=0.2)(d)\n","            if bn:\n","                d = BatchNormalization(momentum=0.8)(d)\n","            return d\n","\n","        img_A = Input(shape=(*self.img_shape[:-1],self.num_class))\n","        img_B = Input(shape=(*self.img_shape[:-1],self.num_class))\n","\n","        # Concatenate image and conditioning image by channels to produce input\n","        combined_imgs = Concatenate(axis=-1)([img_A, img_B])\n","\n","        d1 = d_layer(combined_imgs, self.df, bn=False)\n","        d2 = d_layer(d1, self.df*2)\n","        d3 = d_layer(d2, self.df*4)\n","        d4 = d_layer(d3, self.df*8)\n","\n","        validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n","\n","        return Model([img_A, img_B], validity)\n","\n","    def train(self, epochs, batch_size=1, sample_interval=50):\n","\n","        start_time = datetime.datetime.now()\n","\n","        # Adversarial loss ground truths\n","        valid = np.ones((batch_size,) + self.disc_patch)\n","        fake = np.zeros((batch_size,) + self.disc_patch)\n","\n","        for epoch in range(epochs):\n","            for batch_i, (imgs_A, imgs_B) in enumerate(self.data_loader):\n","\n","                # ---------------------\n","                #  Train Discriminator\n","                # ---------------------\n","\n","                # Condition on B and generate a translated version\n","                real_A = self.generator.predict(imgs_A)\n","                fake_A = self.generator.predict(imgs_B)\n","\n","                # Train the discriminators (original images = real / generated = Fake)\n","                d_loss_real = self.discriminator.train_on_batch([imgs_A, imgs_B], valid)\n","                d_loss_fake = self.discriminator.train_on_batch([fake_A, imgs_B], fake)\n","                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","\n","                # -----------------\n","                #  Train Generator\n","                # -----------------\n","\n","                # Train the generators\n","                g_loss = self.combined.train_on_batch([imgs_A, imgs_B], [valid, imgs_A])\n","\n","                elapsed_time = datetime.datetime.now() - start_time\n","                # Plot the progress\n","                print (\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %f] time: %s\" % (epoch, epochs,\n","                                                                        batch_i, self.data_loader.n_batches,\n","                                                                        d_loss[0], 100*d_loss[1],\n","                                                                        g_loss[0],\n","                                                                        elapsed_time))\n","\n","                # If at save interval => save generated image samples\n","                if batch_i % sample_interval == 0:\n","                    self.sample_images(epoch, batch_i)\n","\n","    def sample_images(self, epoch, batch_i):\n","        os.makedirs('images/%s' % self.dataset_name, exist_ok=True)\n","        r, c = 3, 3\n","\n","        imgs_A, imgs_B = self.data_loader.load_data(batch_size=3, is_testing=True)\n","        fake_A = self.generator.predict(imgs_B)\n","\n","        gen_imgs = np.concatenate([imgs_B, fake_A, imgs_A])\n","\n","        # Rescale images 0 - 1\n","        gen_imgs = 0.5 * gen_imgs + 0.5\n","\n","        titles = ['Condition', 'Generated', 'Original']\n","        fig, axs = plt.subplots(r, c)\n","        cnt = 0\n","        for i in range(r):\n","            for j in range(c):\n","                axs[i,j].imshow(gen_imgs[cnt])\n","                axs[i, j].set_title(titles[i])\n","                axs[i,j].axis('off')\n","                cnt += 1\n","        fig.savefig(\"images/%s/%d_%d.png\" % (self.dataset_name, epoch, batch_i))\n","        plt.close()\n"],"execution_count":0,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-2a1b47e4483f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m     \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDANet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m     \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'dataset'"]}]},{"cell_type":"code","metadata":{"id":"Cc09wjdyguV0","colab_type":"code","colab":{}},"source":["if __name__ == '__main__':\n","    gan = DANet()\n","    gan.train(epochs=200, batch_size=1, sample_interval=200)"],"execution_count":0,"outputs":[]}]}